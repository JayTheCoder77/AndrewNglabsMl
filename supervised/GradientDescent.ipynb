{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c80c8732-e70a-4c4c-b147-8c8becebc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "838f7615-22f3-4b0d-9e6c-5a3f2f2a200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbe5d8bb-7665-448e-90d8-4c77e7bf0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([1.0,2.0])\n",
    "y_train = np.array([300.0,500.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acbd580d-c334-4325-b30c-e8c86d7be444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([1.0, 1.7, 2.0, 2.5, 3.0, 3.2])\n",
    "y_train = np.array([250, 300, 480,  430,   630, 730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3cdc6247-c869-4f5e-886d-544cd92522c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x,y,w,b):\n",
    "    cost_sum = 0\n",
    "    m = x.shape[0]\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = (f_wb - y[i]) ** 2\n",
    "        cost_sum = cost_sum + cost\n",
    "    total_cost = cost_sum * (1/(2 * m))\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65bf98e1-184b-41e1-9e78-41f82910f9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4700.0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(X_train,y_train,200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a260448-539d-4b5f-95d1-61ee46ecad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x , y , w ,b ):\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        dj_dw = dj_dw + (f_wb - y[i]) * x[i]\n",
    "        dj_db = dj_db + (f_wb - y[i])\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    return dj_dw , dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a68bfc2e-f449-4c96-a166-b6f91d5e293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,y,w_in,b_in,alpha,num_iters,cost_function,gradient_function):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to fit w,b. Updates w,b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,))  : Data, m examples \n",
    "      y (ndarray (m,))  : target values\n",
    "      w_in,b_in (scalar): initial values of model parameters  \n",
    "      alpha (float):     Learning rate\n",
    "      num_iters (int):   number of iterations to run gradient descent\n",
    "      cost_function:     function to call to produce cost\n",
    "      gradient_function: function to call to produce gradient\n",
    "      \n",
    "    Returns:\n",
    "      w (scalar): Updated value of parameter after running gradient descent\n",
    "      b (scalar): Updated value of parameter after running gradient descent\n",
    "      J_history (List): History of cost values\n",
    "      p_history (list): History of parameters [w,b] \n",
    "      \"\"\"\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw , dj_db = gradient_function(x,y,w,b)\n",
    "\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(x,y,w,b))\n",
    "            p_history.append([w,b])\n",
    "        # print\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "    return w,b,J_history,p_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d756f5f-f108-4b8a-bafe-ef45de10d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 1.09e+05  dj_dw: -1.170e+03, dj_db: -4.700e+02   w:  1.170e+01, b: 4.70000e+00\n",
      "Iteration 1000: Cost 1.78e+03  dj_dw: -1.060e+00, dj_db:  2.599e+00   w:  1.974e+02, b: 3.16325e+01\n",
      "Iteration 2000: Cost 1.74e+03  dj_dw: -4.357e-01, dj_db:  1.068e+00   w:  2.045e+02, b: 1.44256e+01\n",
      "Iteration 3000: Cost 1.74e+03  dj_dw: -1.790e-01, dj_db:  4.388e-01   w:  2.074e+02, b: 7.35495e+00\n",
      "Iteration 4000: Cost 1.74e+03  dj_dw: -7.357e-02, dj_db:  1.803e-01   w:  2.085e+02, b: 4.44950e+00\n",
      "Iteration 5000: Cost 1.74e+03  dj_dw: -3.023e-02, dj_db:  7.410e-02   w:  2.090e+02, b: 3.25559e+00\n",
      "Iteration 6000: Cost 1.74e+03  dj_dw: -1.242e-02, dj_db:  3.045e-02   w:  2.092e+02, b: 2.76500e+00\n",
      "Iteration 7000: Cost 1.74e+03  dj_dw: -5.104e-03, dj_db:  1.251e-02   w:  2.093e+02, b: 2.56340e+00\n",
      "Iteration 8000: Cost 1.74e+03  dj_dw: -2.097e-03, dj_db:  5.141e-03   w:  2.093e+02, b: 2.48056e+00\n",
      "Iteration 9000: Cost 1.74e+03  dj_dw: -8.619e-04, dj_db:  2.113e-03   w:  2.094e+02, b: 2.44652e+00\n",
      "(w,b) found by gradient descent: (209.3590,  2.4325)\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "tmp_alpha = 1.0e-2\n",
    "\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(X_train, y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "print(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e17af8b-ce05-4f24-8b9c-9f7cc8d82b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(211.79149609143826)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 sqft house prediction\n",
    "y_predict = w_final * 1.0 + b_final\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddd14c-f2ec-4f81-ad0c-bc116209ad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
