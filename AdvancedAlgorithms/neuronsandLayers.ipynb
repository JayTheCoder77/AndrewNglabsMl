{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71c3b77",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "d71c3b77"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuron without activation - regression/linear model"
      ],
      "metadata": {
        "id": "4gSk8_2jtoMj"
      },
      "id": "4gSk8_2jtoMj"
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "X_train = np.array([[1.0] , [2.0]] , dtype=np.float32) #(size in 1000 square feet)\n",
        "Y_train = np.array([[300.0], [500.0]], dtype=np.float32) #(price in 1000s of dollars)"
      ],
      "metadata": {
        "id": "w4_8jYa6thFb"
      },
      "id": "w4_8jYa6thFb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can define a layer with one neuron or unit and compare it to the familiar linear regression function.\n",
        "linear_layer = tf.keras.layers.Dense(units=1 , activation='linear',)"
      ],
      "metadata": {
        "id": "bgvesdJBuCuH"
      },
      "id": "bgvesdJBuCuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine the weights\n",
        "linear_layer.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNHJ-pUSuOAp",
        "outputId": "582ff497-942f-49f8-9e87-cf14805eaee4"
      },
      "id": "LNHJ-pUSuOAp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no weights as the weights are not yet instantiated. Let's try the model on one example in X_train. This will trigger the instantiation of the weights. Note, the input to the layer must be 2-D, so we'll reshape it."
      ],
      "metadata": {
        "id": "rgWnL0RquYgA"
      },
      "id": "rgWnL0RquYgA"
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = linear_layer(X_train[0].reshape(1,1))\n",
        "print(a1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI8gQClGuTjr",
        "outputId": "b47ea2b8-3cd4-40c2-e909-8751e059f84b"
      },
      "id": "bI8gQClGuTjr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.2003454]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a tensor (another name for an array) with a shape of (1,1) or one entry.\n",
        "Now let's look at the weights and bias. These weights are randomly initialized to small numbers and the bias defaults to being initialized to zero."
      ],
      "metadata": {
        "id": "0SG-03hvaEjT"
      },
      "id": "0SG-03hvaEjT"
    },
    {
      "cell_type": "code",
      "source": [
        "w, b= linear_layer.get_weights()\n",
        "print(f\"w = {w}, b={b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teJxXU0faE-o",
        "outputId": "e13e6f92-d721-41d9-bc26-0c6bc9690288"
      },
      "id": "teJxXU0faE-o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [[0.2003454]], b=[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_w = np.array([[200]])\n",
        "set_b = np.array([100])\n",
        "\n",
        "# set_weights takes a list of numpy arrays\n",
        "linear_layer.set_weights([set_w, set_b])\n",
        "print(linear_layer.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8W5CjsoaJNB",
        "outputId": "7962304d-3c25-45d2-816f-eaf13c9c0132"
      },
      "id": "A8W5CjsoaJNB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[200.]], dtype=float32), array([100.], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compariing linear layer with layer output - they both are same !\n",
        "a1 = linear_layer(X_train[0].reshape(1,1))\n",
        "print(a1)\n",
        "alin = np.dot(set_w , X_train[0].reshape(1,1)) + set_b\n",
        "print(alin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsZo6gn-atXK",
        "outputId": "accca63e-1942-4fcd-af73-efada01f8880"
      },
      "id": "MsZo6gn-atXK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[300.]], shape=(1, 1), dtype=float32)\n",
            "[[300.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They produce the same values! Now, we can use our linear layer to make predictions on our training data."
      ],
      "metadata": {
        "id": "WSfnk9oCbLre"
      },
      "id": "WSfnk9oCbLre"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_tf = linear_layer(X_train)\n",
        "prediction_np = np.dot( X_train, set_w) + set_b"
      ],
      "metadata": {
        "id": "1owyvM1gbAz6"
      },
      "id": "1owyvM1gbAz6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "our tensorflow and numpy predictions are same so we are good to go"
      ],
      "metadata": {
        "id": "1H78ngzGbdyH"
      },
      "id": "1H78ngzGbdyH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neuron with Sigmoid activation\n",
        "The function implemented by a neuron/unit with a sigmoid activation is the same as in Course 1, logistic  regression:\n",
        "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
        "where $$g(x) = sigmoid(x)$$\n",
        "\n",
        "Let's set $w$ and $b$ to some known values and check the model.\n"
      ],
      "metadata": {
        "id": "YCB-bD-Ybdsr"
      },
      "id": "YCB-bD-Ybdsr"
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # 2-D Matrix\n",
        "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # 2-D Matrix"
      ],
      "metadata": {
        "id": "YhHWKZvxbqXC"
      },
      "id": "YhHWKZvxbqXC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = Y_train == 1\n",
        "neg = Y_train == 0"
      ],
      "metadata": {
        "id": "poZbinC9bvVL"
      },
      "id": "poZbinC9bvVL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Neuron\n",
        "We can implement a 'logistic neuron' by adding a sigmoid activation. The function of the neuron is then described by (2) above.\n",
        "This section will create a Tensorflow Model that contains our logistic layer to demonstrate an alternate method of creating models. Tensorflow is most often used to create multi-layer models. The Sequential model is a convenient means of constructing these models."
      ],
      "metadata": {
        "id": "r4Nfs4Cab0O6"
      },
      "id": "r4Nfs4Cab0O6"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(1, input_dim=1 , activation='sigmoid', name='L1')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfDuvbucbyRK",
        "outputId": "19863ece-c77d-41f2-a4e1-f5721ed3bb35"
      },
      "id": "EfDuvbucbyRK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "_-tpkNG_cI18",
        "outputId": "49150ac6-2c31-4dc3-873f-af0283e6777a"
      },
      "id": "_-tpkNG_cI18",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ L1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_layer = model.get_layer('L1')\n",
        "w , b = logistic_layer.get_weights()\n",
        "print(w,b)\n",
        "print(w.shape,b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO3hcC1ScLAg",
        "outputId": "a4ad70dc-6aaf-4a31-e8f3-12745ed499d6"
      },
      "id": "VO3hcC1ScLAg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.800856]] [0.]\n",
            "(1, 1) (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set the weight and bias to some known values."
      ],
      "metadata": {
        "id": "o4G5NjDcca29"
      },
      "id": "o4G5NjDcca29"
    },
    {
      "cell_type": "code",
      "source": [
        "set_w = np.array([[2]])\n",
        "set_b = np.array([-4.5])\n",
        "\n",
        "# set_weights takes a list of numpy arrays\n",
        "logistic_layer.set_weights([set_w, set_b])\n",
        "print(logistic_layer.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHZGDGTfcYmR",
        "outputId": "555bdfe5-f1ae-45cc-cc88-7270de34f69d"
      },
      "id": "rHZGDGTfcYmR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[2.]], dtype=float32), array([-4.5], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoidnp(z):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of z\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    z : array_like\n",
        "        A scalar or numpy array of any size.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "     g : array_like\n",
        "         sigmoid(z)\n",
        "    \"\"\"\n",
        "    z = np.clip( z, -500, 500 )           # protect against overflow\n",
        "    g = 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "    return g"
      ],
      "metadata": {
        "id": "wNtBxMzIdCr_"
      },
      "id": "wNtBxMzIdCr_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = model.predict(X_train[0].reshape(1,1))\n",
        "print(a1)\n",
        "alog = alog = sigmoidnp(np.dot(set_w,X_train[0].reshape(1,1)) + set_b)\n",
        "print(alog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJDXt7Pqck9s",
        "outputId": "e6aa309b-2832-45b7-d9bc-557fbf1f198f"
      },
      "id": "fJDXt7Pqck9s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n",
            "[[0.01098694]]\n",
            "[[0.01098694]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZHtz1vedDL8"
      },
      "id": "QZHtz1vedDL8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}